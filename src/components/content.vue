<template>
<div id="chat-container">  
    <div class="top">
        <div class="block">
          <img src="../image/logo2.png" alt="">
        </div>
        <div style="text-align: center;" >{{ status }}</div>
         <span v-loading="true" style="width: 10px;height: 10px;top: 50px;margin-left: 220px;"></span>
    </div>
    <div class="mid">
      <div style="text-align: center;">    {{ prompt }}</div>
        </div>
<div class="bottom">

   <el-button v-show="isshow"  @click="stopCord" circle style="width:70px;height: 70px;margin-left: 120px;" >
     <img src="../image/micophone.png" style="width: 30px;height: auto;" alt="">
  </el-button>
  <el-button v-show="!isshow"  @click="startCord" circle style="width:70px;height: 70px;margin-left: 120px;" >
     <img src="../image/stopmico.png" style="width: 30px;height: auto;" alt="">
  </el-button>
  <el-button circle @click="notifyParent" style="width:70px;height: 70px;margin-left: 120px;">
       <img src="../image/close.png" style="width: 30px;height: auto;" alt="">
  </el-button>
</div>
 
</div>

</template>
<script setup>
import { onMounted, ref } from 'vue';
import RecordRTC from 'recordrtc';
import { chat, getText } from '@/utils/api';

const prompt=ref('ä½ å¯ä»¥å¼€å§‹è¯´è¯äº†')
const isshow=ref(true)
const status=ref('')
// å®šä¹‰äº‹ä»¶
const emit = defineEmits(['childEvent','send-data'])

const notifyParent = () => {
  // è§¦å‘äº‹ä»¶å¹¶ä¼ é€’æ•°æ®
  isshow.value=false
  emit('childEvent', false)
    if (!recorder) return;
  recorder.stopRecording(() => {
    isRecording.value = false;
    audioBlob.value = recorder.getBlob();
    console.log(audioBlob.value)
    audioUrl.value = URL.createObjectURL(audioBlob.value);
    
    // åœæ­¢åª’ä½“æµ
    mediaStream.getTracks().forEach(track => track.stop());
  });
}
let mediaStream = null;
const isRecording = ref(false);
const audioBlob = ref(null);
const audioUrl = ref('');
let recorder = null;
const volume = ref(0);
let audioContext, processor, source;
const startCord=()=>{
  prompt.value="æ‚¨å¯ä»¥å¼€å§‹è¯´è¯äº†"
isshow.value=!isshow.value
startRecording()
}
const stopCord=()=>{
  isshow.value=!isshow.value
    if (!recorder) return;
  recorder.stopRecording(() => {
    isRecording.value = false;
    audioBlob.value = recorder.getBlob();
    console.log(audioBlob.value)
    audioUrl.value = URL.createObjectURL(audioBlob.value);
    
    // åœæ­¢åª’ä½“æµ
    mediaStream.getTracks().forEach(track => track.stop());
  });
    prompt.value="æ‚¨å·²é™éŸ³ ğŸ”‡"
    console.log(prompt.value)
}
const startRecording = async () => {
  try {
    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    audioContext = new (window.AudioContext || window.webkitAudioContext)();
    source = audioContext.createMediaStreamSource(mediaStream);
    processor = audioContext.createScriptProcessor(2048, 1, 1);
    source.connect(processor);
    processor.connect(audioContext.destination);
    
    processor.onaudioprocess = processAudio;

    recorder = new RecordRTC(mediaStream, {
      type: 'audio',
      mimeType: 'audio/mpeg', // ä¿®æ”¹ä¸ºMP3ç±»å‹
      recorderType: RecordRTC.StereoAudioRecorder,
      audioBitsPerSecond: 128000, // 128kbpsæ¯”ç‰¹ç‡
      desiredSampRate: 44100, // é‡‡æ ·ç‡
      numberOfAudioChannels: 1 // å•å£°é“
    });
    
    recorder.startRecording();
    isRecording.value = true;
    audioBlob.value = null;
    audioUrl.value = '';
  } catch (error) {
    console.error('æ— æ³•è®¿é—®éº¦å…‹é£:', error);
    alert('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®');
  }
};
function debounce(func, wait = 300) {
  let timeout;
  return function(...args) {
    clearTimeout(timeout);
    timeout = setTimeout(() => {
      func.apply(this, args);
    }, wait);
  };
}

// åˆ›å»ºé˜²æŠ–å‡½æ•°å®ä¾‹
const debouncedSoundAlert = debounce(() => {
  console.log("æ£€æµ‹åˆ°å£°éŸ³ ğŸ”Š");
  stopRecording()
}, 3000);

const debouncedSilenceAlert = debounce(() => {
  console.log("é™éŸ³ ğŸ”‡");
}, 3000);
const processAudio = (event) => {
  const inputBuffer = event.inputBuffer;
  const inputData = inputBuffer.getChannelData(0);
  
  // è®¡ç®—éŸ³é‡ (RMS)
  let sum = 0;
  for (let i = 0; i < inputData.length; i++) {
    sum += inputData[i] ** 2;
  }
  const rms = Math.sqrt(sum / inputData.length);
  volume.value = rms;
  
  // åˆ¤æ–­æ˜¯å¦æœ‰å£°éŸ³ (é˜ˆå€¼éœ€è¦æ ¹æ®ç¯å¢ƒè°ƒæ•´)
  const THRESHOLD = 0.1; 
  if (rms > THRESHOLD) {
    if(isshow.value){
 prompt.value="é™éŸ³ä¸­ ğŸ”‡"
    }
    debouncedSoundAlert(); // è§¦å‘å£°éŸ³æç¤º
  } else {
    if(isshow.value){
 prompt.value="å£°éŸ³æ£€æµ‹ä¸­ ğŸ”Š"
    }
    debouncedSilenceAlert(); // è§¦å‘é™éŸ³æç¤º
  }
};
const stopRecording = () => {
  if (!recorder) return;
  recorder.stopRecording(() => {
    isRecording.value = false;
    audioBlob.value = recorder.getBlob();
    console.log(audioBlob.value)
    audioUrl.value = URL.createObjectURL(audioBlob.value);
    
    // åœæ­¢åª’ä½“æµ
    mediaStream.getTracks().forEach(track => track.stop());
      sendRecording()
  });
};
const audioPlayer = ref(null);
const isPlaying = ref(false);

const sendMessage = (res) => {
  emit('send-data',res);
};
const sendRecording = async () => {
  if (!audioBlob.value) return;
  try {
    const formData = new FormData();
    const id=localStorage.getItem("id")
    let isNewDialog=id==1000?"true":"false"
    let gender=localStorage.getItem('gender')
    let token=localStorage.getItem('token')
    status.value="è¯­éŸ³è¯†åˆ«ä¸­..."
    formData.append('audiofile', audioBlob.value); // ä¿®æ”¹ä¸º.mp3åç¼€
    formData.append('isNewDialog',isNewDialog)
    formData.append("dialog_id",id)
    formData.append('gender',gender)
    formData.append('token',token)
    chat(formData).then(res=>{
      console.log(res)
      if(res.is_null=="true"){
        console.log("å‘é€çš„å£°éŸ³ä¸ºç©º")
        status.value="æœªè¯†åˆ«åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯´ï¼"
        startRecording()
        return ;
      }
      console.log(res)
      sendMessage(res)
      localStorage.setItem("id",res.dialog_id)
       const byteCharacters = atob(res.audio);
  const byteArrays = [];
  
  for (let offset = 0; offset < byteCharacters.length; offset += 1024) {
    const slice = byteCharacters.slice(offset, offset + 1024);
    const byteNumbers = new Array(slice.length);
    
    for (let i = 0; i < slice.length; i++) {
      byteNumbers[i] = slice.charCodeAt(i);
    }
    
    byteArrays.push(new Uint8Array(byteNumbers));
  }
 const blob = new Blob(byteArrays, { type: 'audio/mpeg' });
            const url = URL.createObjectURL(blob);
     if (audioPlayer.value) {
      URL.revokeObjectURL(audioPlayer.value.src);
    }
   
     audioPlayer.value = new Audio(url);
      console.log(audioPlayer.value)
	    // æ’­æ”¾éŸ³é¢‘
      status.value="è¯´è¯ä¸­..."
    audioPlayer.value.play()
      .then(() => {
        isPlaying.value = true;
      })
      .catch(e => {
        console.error("æ’­æ”¾å¤±è´¥:", e);
        isPlaying.value = false;
      });
 
     // ç›‘å¬æ’­æ”¾ç»“æŸäº‹ä»¶
    audioPlayer.value.onended = () => {
      isPlaying.value = false;
        status.value=""
      if(isshow.value){
              setTimeout(()=>{
        console.log("å¼€å§‹å½•éŸ³")
startRecording()
      })
      }

      
    };
      audioBlob.value = null;
      audioUrl.value = '';
    })

  } catch (error) {
    console.error('å‘é€å½•éŸ³å‡ºé”™:', error);
    alert('å‘é€å½•éŸ³æ—¶å‡ºé”™');
  }
};
onMounted(()=>{
  startRecording()
})

</script>
<style scoped>
.top{
  height:70vh;
}
.block{
  text-align: center;
padding-top: 30vh;

}
.mid{
  height:10vh;
}
img{
  width:100px;
  height:100px;
  border-radius: 50px;
}

</style>